Village of Words: 로컬 LLM 기반 자율 NPC 사회 실험
설계 및 정량 평가
1. 서론 및 문제의식
대규모 언어 모델(LLM)의 발달은 인간과 유사한 자연어 상호작용을 가능하게 하며, 이를 기반으로 한 자율 에이전트
(LLM as Agent)에 대한 연구도 급증하고 있다. 특히 최근에는 개별 LLM들을 하나의 사회 구성원처럼 배치하여, 그들
간의 상호작용을 통해 협력, 감정, 계획, 기억 등 다양한 사회적 행동을 시뮬레이션하려는 시도가 주목받고 있다. 대표적
으로 Park et al. (2023)이 제안한 Generative Agents는 마을 내에서 생활하는 가상의 LLM 캐릭터들이 인간처럼 정보
를 기억하고, 사회적 네트워크를 형성하며, 일과를 수행하는 시스템을 구현함으로써 LLM의 에이전트화 가능성을 실증
했다.
그러나 이러한 선행 연구들은 공통적으로 실험 설계와 평가 방식에서 한계를 드러낸다. 첫째, 상호작용의 결과가 모두
자연어로 생성되기 때문에 정량적인 평가가 어렵다. 대부분의 논문은 대화 로그를 수동으로 분석하거나 특정 장면을 해
석하는 방식으로 결과를 제시하며, 이를 수치화하거나 비교 가능한 구조로 만드는 데에는 실패했다. 이는 결과의 객관성
과 일반화 가능성을 제한한다. 둘째, 평가가 주로 정성적 서술에 의존함에 따라 실험의 재현성이 떨어진다. 동일한 조건
에서 동일한 결과가 나오는지를 검증할 수 없기 때문에, 새로운 설계를 비교하거나 검증하는 데 어려움이 존재한다. 셋
째, 실험 환경이 웹 기반 인터페이스에 지나치게 의존함으로써 실험의 확장성과 통제가 어렵다. 예를 들어 Generative
 Agents에서는 Unity 기반의 시각적 마을 환경이 도입되었고, 이는 연구자가 직접 개별 이벤트를 트리거하거나 상세 로
그를 수집하는 데 구조적 제약을 초래했다.
이와 같은 배경에서, 본 연구는 다중 자율 LLM 에이전트가 구성하는 작은 사회에서 협력이라는 사회적 메커니즘이 어떻
게 형성되고, 유지되며, 특정 조건 하에서 어떻게 붕괴되는지를 정량적으로 추적할 수 있는 실험 프레임워크를 제안하고
자 한다. 기존 연구에서 협력의 개념은 등장하더라도, 그것이 어떤 계기로 발생했는지, 어떻게 유지되었는지, 왜 특정 시
점에 무너졌는지를 수치화하고 분석한 사례는 매우 드물다. 그 이유는 세 가지로 정리할 수 있다. 첫째, 자연어 출력이
비형식적이기 때문에 협력 행동 자체를 명확히 정의하거나 분류하기 어렵다. 둘째, 평가 기준이 불분명하여 어떤 행동이
협력이고 어떤 행동이 이기적인지를 판단할 수 있는 명시적 기준이 부재하다. 셋째, 에이전트 간의 상호작용 로그가 통
제되지 않은 자유형 대화 로그로 구성되어 있기 때문에 데이터로부터 메커니즘을 추출하기가 어렵다.
본 연구에서는 이러한 문제를 해결하기 위해 다음과 같은 실험 조건을 제안한다. 첫째, CLI 기반의 실험 환경을 구성하여
시각적 요소를 모두 제거함으로써 에이전트 간 상호작용이 오직 언어로만 이루어지도록 설계한다. 이는 외부 요인의 간
섭을 차단하고, 모든 상호작용이 로그 형태로 구조화되어 수집되도록 한다. CLI 환경은 단순히 기술적으로 구현이 용이
하다는 점을 넘어서, 실험의 재현성과 통제 가능성을 극대화할 수 있다는 점에서 의의가 있다. 둘째, 로컬 LLM(LM
 Studio 기반)을 활용하여 네트워크 환경에 영향을 받지 않고 언제든 동일한 조건에서 실험을 재현할 수 있도록 한다.
 LM Studio는 여러 개의 LLM을 로컬 환경에서 동시에 구동할 수 있으며, 에이전트 별로 포트를 분리하거나 요청 스레드
를 분산하여 운영할 수 있기 때문에 병렬적인 사회 시뮬레이션 실험에도 적합하다. 셋째, 각 에이전트의 출력은 JSON
형태로 구조화되며, 발화 의도, 실제 행동, 내부 결정 등을 명시적으로 구분하도록 프롬프트를 구성한다. 이를 통해 협력
여부를 자동으로 판단할 수 있으며, 평가 지표의 수치화가 가능해진다.
정량 평가 지표는 기존의 사회적 협력 실험, 특히 Public Goods Game(Kulkarni & Brunswicker, 2024), LLM 기반
협상 실험(Abdelnabi et al., 2024), MultiAgentBench(2025) 등에서 실제로 사용되거나 제안된 지표들을 참고하여
구성하였다. 예를 들어 협력 지속 시간, 기여 총합, Gini 계수, 대화량 집중도, 회복 시간 등은 모두 기존 실험에서 사용된
바 있으며, 본 실험에서는 CLI 기반 시스템 구조에 맞게 이를 자동 계산 가능하도록 설계하였다.
따라서 본 연구의 목적은 단순히 자율 에이전트가 협력할 수 있는지를 보는 것이 아니라, 그러한 협력이 어떤 경로로 형
성되며, 어떠한 위기를 계기로 붕괴되고, 그 후 어떻게 회복되는지를 정량적으로 추적 가능한 구조 속에서 검증하는 데
있다. 이 실험이 성공적으로 수행된다면, 기존 Generative Agents와 같은 연구가 제공하지 못했던 수치 기반 사회 시뮬
레이션의 기반을 제시할 수 있으며, 향후에는 정책 적용 실험, 윤리 기반 시뮬레이션, 자원 분배 모델 테스트 등으로 확
1
장 가능하다. 또한 평가 지표가 구조화되어 있으므로, 향후 다른 연구자가 동일한 실험 구조에 다른 조건을 삽입하여 비
교 실험을 수행할 수 있는 재현성 기반을 제공한다.
관련 연구는 Generative Agents(Park et al., 2023), MetaGPT(Hong et al., 2023), Voyager(Xu et al., 2023),
 MultiAgentBench(2024), Public Goods Game 기반 실험(Kulkarni & Brunswicker, 2024), 협상 프레임워크
(Abdelnabi et al., 2024)를 중심으로 선정하였다. 각각의 연구는 LLM 에이전트의 자율성, 협력 구조, 메모리 기반 행
동, 강화학습과의 통합 등 다양한 강점을 보여주었으나, 협력의 형성–유지–붕괴라는 사회적 메커니즘을 정량적으로 추
적하거나 자동 평가 가능한 구조로 제시하지는 않았다. 본 연구는 그 한계를 보완하며, 기술적 실현 가능성과 평가 설계
의 정교함을 동시에 확보하고자 한다